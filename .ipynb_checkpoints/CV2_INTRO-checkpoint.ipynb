{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('photo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('cat',img)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    nframe = reshape(frame)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('nfarme',nframe)\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank[:] = 0,244,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank\n",
    "cv.imshow('blank',blank)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.circle(blank,(250,250),30,(0,70,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(image, scale = 0.75):\n",
    "    h = int(image.shape[0]*0.75)\n",
    "    w = int(image.shape[1]*0.75)\n",
    "    dim = (w,h)\n",
    "    return cv.resize(image,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('blank',blank)\n",
    "cv.waitKey(0)\n",
    "rimg = reshape(blank)\n",
    "cv.imshow(\"blanssc\",rimg)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('circle',blank)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.line(blank,(0,0),(250,250),(230,30,10),1)\n",
    "cv.imshow('circleline',blank)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grey\n",
    "def grey(image):\n",
    "    return cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur\n",
    "def blur(image):\n",
    "    return cv.blur(image,(7,7), cv.BORDER_DEFAULT)\n",
    "\n",
    "#edge\n",
    "def edge(image):\n",
    "    return cv.Canny(image,125,300)\n",
    "\n",
    "#dilate\n",
    "def dilate(image):\n",
    "    return cv.dilate(image,(7,7),iterations=3)\n",
    "\n",
    "#erode\n",
    "def erode(image):\n",
    "    return cv.erode(image, (3,3), iterations=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    greyframe = grey(frame)\n",
    "    blurframe = blur(frame)\n",
    "    edgeframe = edge(frame)\n",
    "    dilateframe = dilate(edgeframe)\n",
    "    erodeframe = erode(edgeframe)\n",
    "   \n",
    "    ######## Display the resulting frame\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('greyfarme',greyframe)\n",
    "    cv.imshow('blurfarme',blurframe)\n",
    "    cv.imshow('edgefarme',edgeframe)\n",
    "    cv.imshow('dilatefarme',dilateframe)\n",
    "    cv.imshow('erodefarme',erodeframe)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE TRANSFORMATION\n",
    "#crop\n",
    "def crop(image):\n",
    "    return image[50:300, 200:400]\n",
    "\n",
    "#flip\n",
    "def flip(image):\n",
    "    return cv.flip(image,0)\n",
    "\n",
    "#rotate\n",
    "def rotate(image, angle, rotPoint=None ):\n",
    "    (height,width) = image.shape[:2] \n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width,height)\n",
    "    \n",
    "    return cv.warpAffine(image, rotMat, dimensions)\n",
    "    \n",
    "#translate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    cropframe = crop(frame)\n",
    "\n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('cropfarme',cropframe)\n",
    "\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour detection\n",
    "def contour_detect(image):\n",
    "    contours, heirarchies = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "#draw contour\n",
    "def contour_draw(cont, image):\n",
    "    blank = np.zeros(image.shape, dtype='uint8')\n",
    "    return cv.drawContours(blank, cont, -1, (0,0,255), 1)\n",
    "    \n",
    "#threshold(binarise)\n",
    "def thresh(image):\n",
    "    ret, thresh = cv.threshold(image,125,255, cv.THRESH_BINARY)\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    threshframe = thresh(greyframe)\n",
    "    contour = contour_detect(edgeframe) #use canny->contours\n",
    "    contourframe = contour_draw(contour, frame)\n",
    "    \n",
    "    ######## Display the resulting frame\n",
    "    \n",
    "    cv.imshow('threshold', threshframe)\n",
    "    cv.imshow('contour_draw', contourframe)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLOR\n",
    "\n",
    "#BGR to GREY\n",
    "def bgr_to_grey(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "#GREY to BGR\n",
    "def grey_to_bgr(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "#BGR to HSV\n",
    "def bgr_to_hsv(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "#HSV to BGR\n",
    "def hsv_to_bgr(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_HSV2BGR)\n",
    "\n",
    "#BGR to LAB\n",
    "def bgr_to_lab(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2LAB)\n",
    "#LAB to BGR\n",
    "def lab_to_bgr(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_LAB2BGR)\n",
    "\n",
    "#BGR to RGB\n",
    "def bgr_to_rgb(image):\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "#GREY to HSV/LAB #grey-->bgr-->hsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    greyframe = bgr_to_grey(frame)\n",
    "#     bgr__greyframe = grey_to_bgr(frame)\n",
    "    hsvframe = bgr_to_hsv(frame)\n",
    "    bgr__hsvframe = hsv_to_bgr(frame)\n",
    "    labframe = bgr_to_lab(frame)\n",
    "    bgr__labframe = lab_to_bgr(frame)\n",
    "    \n",
    "    ######## Display the resulting frame\n",
    "    \n",
    "    cv.imshow('greyframe', greyframe)\n",
    "#     cv.imshow('bgr__greyframe', bgr__greyframe)\n",
    "    cv.imshow('hsvframe', hsvframe)\n",
    "    cv.imshow('bgr__hsvframe', bgr__hsvframe)\n",
    "    cv.imshow('labframe', labframe)\n",
    "    cv.imshow('bgr__labframe', bgr__labframe)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLOR CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    #SPLIT BGR\n",
    "    b,g,r = cv.split(frame)\n",
    "    \n",
    "    #COMBINE BGR\n",
    "    merge = cv.merge([b,g,r])\n",
    "    \n",
    "    #MONO\n",
    "    blank = np.zeros(frame.shape[:2], dtype=\"uint8\")\n",
    "    blue = cv.merge([b,blank,blank])\n",
    "    green = cv.merge([blank,g,blank])\n",
    "    red = cv.merge([blank,blank, r])\n",
    "    \n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('b', b)\n",
    "    cv.imshow('g', g)\n",
    "    cv.imshow('r', r)\n",
    "    cv.imshow('merge', merge)\n",
    "    cv.imshow('blue', blue)\n",
    "    cv.imshow('green', green)\n",
    "    cv.imshow('red', red)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLURRING\n",
    "\n",
    "#averaging blur\n",
    "def blur(image):\n",
    "    return cv.blur(image, (3,3))\n",
    "\n",
    "#gaussian blur\n",
    "def gaussian_blur(image):\n",
    "    return cv.GaussianBlur(image, (3,3), 0)\n",
    "\n",
    "#median blur\n",
    "def median_blur(image):\n",
    "    return cv.medianBlur(image, 3)\n",
    "\n",
    "#bilateral blur\n",
    "def bilateral_blur(image):\n",
    "    return cv.bilateralFilter(image, 10, 35, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    avg_blur = blur(frame)\n",
    "    gauss_blur = gaussian_blur(frame)\n",
    "    med_blur = median_blur(frame)\n",
    "    bil_blur = bilateral_blur(frame)\n",
    "    \n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('average', avg_blur)\n",
    "    cv.imshow('gauss_blur', gauss_blur)\n",
    "    cv.imshow('median_blur', med_blur)\n",
    "    cv.imshow('bilateral_blur', bil_blur)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BITWISE OPERATONS\n",
    "\n",
    "blank = np.zeros((600,600), dtype='uint8')\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (100,100), (500, 500), 255, -1 )\n",
    "circle = cv.circle(blank.copy(), (300,300), 250, 255, -1)\n",
    "cv.imshow('recatngle', rectangle)\n",
    "cv.imshow('circle', circle)\n",
    "\n",
    "#AND\n",
    "bw_and = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow('AND', bw_and)\n",
    "\n",
    "#OR\n",
    "bw_or = cv.bitwise_or(rectangle, circle)\n",
    "cv.imshow('OR', bw_or)\n",
    "\n",
    "#XOR\n",
    "bw_xor = cv.bitwise_xor(rectangle, circle)\n",
    "cv.imshow('XOR', bw_xor)\n",
    "\n",
    "#NOT\n",
    "bw_not = cv.bitwise_not(rectangle, circle)\n",
    "cv.imshow('NOT', bw_not)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASKING\n",
    "\n",
    "def masking(image):\n",
    "    blank = np.zeros((image.shape[0],image.shape[1]), dtype='uint8')\n",
    "    circle = cv.circle(blank, (image.shape[1]//2, image.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "    return cv.bitwise_and(image, image, mask=circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    maskframe = masking(frame) \n",
    "  \n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('masking', maskframe)\n",
    " \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THRESHOLD\n",
    "\n",
    "def thresh(image):\n",
    "    #to greyscale\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    threshold, thresh = cv.threshold(grey, 125, 255, cv.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "#threshhold inverse\n",
    "def thresh_inv(image):\n",
    "    #to greyscale\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    threshold, thresh = cv.threshold(grey, 125, 255, cv.THRESH_BINARY_INV)\n",
    "    return thresh\n",
    "\n",
    "#adaptive threshold\n",
    "def adaptive_thresh(image):\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    thresh = cv.adaptiveThreshold(grey, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C ,cv.THRESH_BINARY_INV, 11, 9)\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    threshframe = thresh(frame) \n",
    "    thresh_inv_frame = thresh_inv(frame) \n",
    "    thresh_apadp_frame = adaptive_thresh(frame) \n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('thresh', threshframe)\n",
    "    \n",
    "    cv.imshow('inverse thresh', thresh_inv_frame)\n",
    "    cv.imshow('adaptive thresh', thresh_apadp_frame)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDGE DETECTION\n",
    "\n",
    "#canny\n",
    "def edge(image):\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    return cv.Canny(grey, 125, 175)\n",
    "\n",
    "#laplacian\n",
    "def laplacian(image):\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    lap = cv.Laplacian(grey, cv.CV_64F)\n",
    "    lap = np.uint8(np.absolute(lap))\n",
    "    return lap\n",
    "\n",
    "#sobel-X\n",
    "def sobel_x(image):\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    sobelx = cv.Sobel(image, cv.CV_64F, 1, 0)\n",
    "    return sobelx\n",
    "\n",
    "#sobel-Y\n",
    "def sobel_y(image):\n",
    "    grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    sobely = cv.Sobel(image, cv.CV_64F, 0, 1)\n",
    "    return sobely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True :\n",
    "      \n",
    "    ######## Capture the video frame\n",
    "    ret, frame = vid.read()\n",
    "    edgeframe = edge(frame) \n",
    "    laplaceframe = laplacian(frame) \n",
    "    sobelxframe = sobel_x(frame)\n",
    "    sobelyframe = sobel_y(frame) \n",
    "    sobel_merge = cv.bitwise_or(sobelxframe, sobelyframe)\n",
    "    ######## Display the resulting frame\n",
    "    cv.imshow('edge', edgeframe)\n",
    "    cv.imshow('laplace', laplaceframe)\n",
    "    cv.imshow('sobel-x', sobelxframe)\n",
    "    cv.imshow('sobel-y', sobelyframe)\n",
    "    cv.imshow('sobel_merge', sobel_merge)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
